
#!/usr/bin/env python3
"""Script for freezing TF trained graph so it can be used with LAMMPS and i-PI.

References
----------
https://blog.metaflow.fr/tensorflow-how-to-freeze-a-model-and-serve-it-with-a-python-api-d4f3596b3adc
"""

import logging
import google.protobuf.message
from deepmd.env import tf, FITTING_NET_PATTERN
from deepmd.entrypoints.freeze import _transfer_fitting_net_trainable_variables, _make_node_names

from deepmd.utils.errors import GraphTooLargeError
from deepmd.utils.sess import run_sess
from deepmd.utils.graph import get_pattern_nodes_from_graph_def
from os.path import abspath

# load grad of force module
import deepmd.op

from typing import List, Optional

# nvnmd
from deepmd.nvnmd.utils.fio import FioDic

__all__ = ["freeze_nvnmd"]

log = logging.getLogger(__name__)

def freeze_nvnmd(
    *, checkpoint_folder: str, output: str, node_names: Optional[str] = None, nvnmd_weight: Optional[str] = None, **kwargs
):
    """Freeze the graph in supplied folder.

    Parameters
    ----------
    checkpoint_folder : str
        location of the folder with model
    output : str
        output file name
    node_names : Optional[str], optional
        names of nodes to output, by default None
    """
    # We retrieve our checkpoint fullpath
    checkpoint = tf.train.get_checkpoint_state(checkpoint_folder)
    input_checkpoint = checkpoint.model_checkpoint_path

    # expand the output file to full path
    output_graph = abspath(output)

    # Before exporting our graph, we need to precise what is our output node
    # This is how TF decides what part of the Graph he has to keep
    # and what part it can dump
    # NOTE: this variable is plural, because you can have multiple output nodes
    # node_names = "energy_test,force_test,virial_test,t_rcut"

    # We clear devices to allow TensorFlow to control
    # on which device it will load operations
    clear_devices = True

    # We import the meta graph and retrieve a Saver
    try:
        # In case paralle training
        import horovod.tensorflow as _
    except ImportError:
        pass
    saver = tf.train.import_meta_graph(
        f"{input_checkpoint}.meta", clear_devices=clear_devices
    )

    # We retrieve the protobuf graph definition
    graph = tf.get_default_graph()
    try:
        input_graph_def = graph.as_graph_def()
    except google.protobuf.message.DecodeError as e:
        raise GraphTooLargeError(
            "The graph size exceeds 2 GB, the hard limitation of protobuf."
            " Then a DecodeError was raised by protobuf. You should "
            "reduce the size of your model."
        ) from e
    nodes = [n.name for n in input_graph_def.node]

    # We start a session and restore the graph weights
    with tf.Session() as sess:
        saver.restore(sess, input_checkpoint)
        model_type = run_sess(sess, "model_attr/model_type:0", feed_dict={}).decode("utf-8")
        if "modifier_attr/type" in nodes:
            modifier_type = run_sess(sess, "modifier_attr/type:0", feed_dict={}).decode(
                "utf-8"
            )
        else:
            modifier_type = None
        if node_names is None:
            output_node_list = _make_node_names(model_type, modifier_type)
            different_set = set(output_node_list) - set(nodes)
            if different_set:
                log.warning(
                    "The following nodes are not in the graph: %s. "
                    "Skip freezeing these nodes. You may be freezing "
                    "a checkpoint generated by an old version." % different_set
                )
                # use intersection as output list
                output_node_list = list(set(output_node_list) & set(nodes))
        else:
            output_node_list = node_names.split(",")
        log.info(f"The following nodes will be frozen: {output_node_list}")

        if nvnmd_weight is not None:
            save_weight(sess, nvnmd_weight) # nvnmd
            
        # We use a built-in TF helper to export variables to constants
        output_graph_def = tf.graph_util.convert_variables_to_constants(
            sess,  # The session is used to retrieve the weights
            input_graph_def,  # The graph_def is used to retrieve the nodes
            output_node_list,  # The output node names are used to select the usefull nodes
        )

        # If we need to transfer the fitting net variables
        output_graph_def = _transfer_fitting_net_trainable_variables(
            sess,
            output_graph_def,
            input_graph_def
        )

        # Finally we serialize and dump the output graph to the filesystem
        with tf.gfile.GFile(output_graph, "wb") as f:
            f.write(output_graph_def.SerializeToString())
        log.info(f"{len(output_graph_def.node):d} ops in the final graph.")


def filter_tensorVariableList(tensorVariableList) -> dict:
    """: get the name of variable for NVNMD

    descrpt_attr/t_avg:0
    descrpt_attr/t_std:0
    filter_type_{atom i}/matrix_{layer l}_{atomj}:0
    filter_type_{atom i}/bias_{layer l}_{atomj}:0
    layer_{layer l}_type_{atom i}/matrix:0
    layer_{layer l}_type_{atom i}/bias:0
    final_layer_type_{atom i}/matrix:0
    final_layer_type_{atom i}/bias:0
    """
    nameList = [tv.name for tv in tensorVariableList]
    nameList = [name.replace(':0', '') for name in nameList]
    nameList = [name.replace('/', '.') for name in nameList]

    dic_name_tv = {}
    for ii in range(len(nameList)):
        name = nameList[ii]
        tv = tensorVariableList[ii]
        p1 = name.startswith('descrpt_attr')
        p1 = p1 or name.startswith('filter_type_')
        p1 = p1 or name.startswith('layer_')
        p1 = p1 or name.startswith('final_layer_type_')
        p2 = 'Adam' not in name
        p3 = 'XXX' not in name
        if p1 and p2 and p3:
            dic_name_tv[name] = tv
    return dic_name_tv


def save_weight(sess, file_name: str = 'nvnmd/weight.npy'):
    """: save the dictionary of weight to a npy file
    """
    tvs = tf.global_variables()
    dic_key_tv = filter_tensorVariableList(tvs)
    dic_key_value = {}
    for key in dic_key_tv.keys():
        value = sess.run(dic_key_tv[key])
        dic_key_value[key] = value
    FioDic().save(file_name, dic_key_value)
